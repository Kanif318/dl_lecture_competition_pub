
41024
【1/30】
train time: 407.98 [s]
train loss: 5.5735
train acc: 0.4933
train simple acc: 0.4039
Traceback (most recent call last):
  File "C:\Users\uta_f\Project\dl_lecture_competition_pub\main.py", line 421, in <module>
    main()
  File "C:\Users\uta_f\Project\dl_lecture_competition_pub\main.py", line 386, in main
    train_loss, train_acc, train_simple_acc, train_time = train(model, train_loader, optimizer, criterion, device, train_dataset)
  File "C:\Users\uta_f\Project\dl_lecture_competition_pub\main.py", line 274, in train
    for image, question, answers, mode_answer in dataloader:
  File "C:\Users\uta_f\.virtualenvs\dl_lecture_competition_pub-JWry4h2n\lib\site-packages\torch\utils\data\dataloader.py", line 631, in __next__
    data = self._next_data()
  File "C:\Users\uta_f\.virtualenvs\dl_lecture_competition_pub-JWry4h2n\lib\site-packages\torch\utils\data\dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "C:\Users\uta_f\.virtualenvs\dl_lecture_competition_pub-JWry4h2n\lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\uta_f\.virtualenvs\dl_lecture_competition_pub-JWry4h2n\lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\uta_f\Project\dl_lecture_competition_pub\main.py", line 176, in __getitem__
    image = self.transform(image)
  File "C:\Users\uta_f\.virtualenvs\dl_lecture_competition_pub-JWry4h2n\lib\site-packages\torchvision\transforms\transforms.py", line 95, in __call__
    img = t(img)
  File "C:\Users\uta_f\.virtualenvs\dl_lecture_competition_pub-JWry4h2n\lib\site-packages\torch\nn\modules\module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\uta_f\.virtualenvs\dl_lecture_competition_pub-JWry4h2n\lib\site-packages\torch\nn\modules\module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\uta_f\.virtualenvs\dl_lecture_competition_pub-JWry4h2n\lib\site-packages\torchvision\transforms\transforms.py", line 354, in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
  File "C:\Users\uta_f\.virtualenvs\dl_lecture_competition_pub-JWry4h2n\lib\site-packages\torchvision\transforms\functional.py", line 468, in resize
    return F_pil.resize(img, size=output_size, interpolation=pil_interpolation)
  File "C:\Users\uta_f\.virtualenvs\dl_lecture_competition_pub-JWry4h2n\lib\site-packages\torchvision\transforms\_functional_pil.py", line 250, in resize
    return img.resize(tuple(size[::-1]), interpolation)
  File "C:\Users\uta_f\.virtualenvs\dl_lecture_competition_pub-JWry4h2n\lib\site-packages\PIL\Image.py", line 2293, in resize
    self.load()
  File "C:\Users\uta_f\.virtualenvs\dl_lecture_competition_pub-JWry4h2n\lib\site-packages\PIL\ImageFile.py", line 293, in load
    n, err_code = decoder.decode(b)
KeyboardInterrupt